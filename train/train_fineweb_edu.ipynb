{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39863ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "n_samples = 200_000\n",
    "context_length = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be830d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfb5ad86a4e4b05a5e21ec30770f7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12308abba00f4a9980beb6ec734d4af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40bffb303af4ed2a82574ddf913125f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = \"/nobackup1/wyf/\"\n",
    "\n",
    "# Takes like 30s to load (it's bad)\n",
    "raw_dataset = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\",\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3bc771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating split datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:24<00:00, 2353.33it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2b71b528b34d6ebe140bbef4af7d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03c0ccd6f4c47f6815db0cdf9baa5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "def filter_dataset(dataset, n_samples: int = None):\n",
    "    # filtered = []\n",
    "    # for sample in tqdm(iter(dataset[\"train\"].take(n_samples)), total=n_samples):\n",
    "    #     # IMPORTANT REVERSAL STEP\n",
    "    #     filtered.append(sample[\"text\"][::-1])\n",
    "    # return filtered\n",
    "\n",
    "    return (\n",
    "        dataset\n",
    "            .select_columns([\"text\"])\n",
    "            .map(lambda s: {\"text\": s[\"text\"][::-1]})\n",
    "    )\n",
    "    \n",
    "# 1k examples: 4.0s\n",
    "\n",
    "print(\"Generating split datasets...\")\n",
    "raw_dataset_with_tqdm = [x for x in tqdm(raw_dataset.take(n_samples), total=n_samples)]\n",
    "split_datasets = (\n",
    "    Dataset.from_list(list(raw_dataset_with_tqdm))\n",
    "        .train_test_split(test_size=0.1, seed=0)\n",
    ")\n",
    "datasets = DatasetDict({\n",
    "    \"train\": filter_dataset(split_datasets[\"train\"]),\n",
    "    \"valid\": filter_dataset(split_datasets[\"test\"]),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7d7fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa191952fd14b55af73540d3ac4bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/180 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ca59da478b40929c89730d1baf292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split_name, dataset in datasets.items():\n",
    "    dataset.to_parquet(f\"./data/fineweb_{n_samples}/{split_name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8e380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d1a2a539d642789c6fa95991836c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = DatasetDict({\n",
    "    \"train\": Dataset.from_parquet(f\"./data/fineweb_{n_samples}/train.parquet\"),\n",
    "    \"valid\": Dataset.from_parquet(f\"./data/fineweb_{n_samples}/valid.parquet\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e72b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you've ever marveled at the look of concentration on the face of a child who tries to fit a square block into a square hole or catch a ball in mid-air, you know that playtime isn't just about fun and games. It's serious business — and toys are the tools of the trade.\n",
      "But when it comes to playthings that educate as well as entertain, not all are created equal. Here is an age-wise guide to how kids play, and to the toys that not only thrill but also help kids understand the world, learn social and emotional skills, and stimulate a developing brain.\n",
      "Babies: How They Play\n",
      "Play in the first year of life is all about exploration. Babies use their five senses to learn about the interesting new world around them: Does an object feel hard or soft? Sticky or rough? What does it do if I drop it? Or put it in my mouth? Most play consists of \"tasting\" or mouthing an object and shaking, banging, or dropping it.\n",
      "When your baby develops new motor skills, play becomes more coordinated and complex. For example, at about 4 months old, babies begin to reach for and grasp objects, like a rattle. By 6 or 7 months, that rattle can be transferred between hands. And around 9 months, a newly developed pincer grasp makes it easier for babies to pick up smaller objects, like blocks and other small age-appropriate toys. During this time, play is usually a solitary activity, but playing side-by-side with other babies and imitating activities is common by year's end.\n",
      "As your baby grows, peer interaction will become more important. But the truth is that you are your baby's favorite playmate. Have you ever danced a puppet in front of your baby's face, only to have him grab it and pull it toward his mouth? Or has he ever squealed in anticipation and delight when you creep toward him, saying, \"I'm gonna get you!\"\n",
      "These interactions help your baby learn about language, social relations, and cause-and-effect. Once babies begin to understand how things in the environment relate to each other and how they taste, smell, feel, and sound, babies are ready for the next stage of development: figuring out how they work.\n",
      "Smart Toys for Babies\n",
      "Nursery mobile. Objects dancing above a baby's head while lying in a crib stimulate vision and develop attention span.\n",
      "Mirror. Initially, your baby will be fascinated with the changing face and expressions looking back from the mirror. Over time, your baby will realize that the drooling, smiling baby staring back is actually a reflection. Once this happens, babies become aware of themselves, which leads to more self-discovery as they learn about body parts and where they are.\n",
      "Ring stack. This classic toy features a cone that fits different sized colored rings. At first, babies enjoy holding and mouthing the rings. Later, they practice fine motor skills by fitting the rings onto the cone. Toddlers also learn about colors and numbers when you count the multicolored rings as you stack them.\n",
      "Push-pull toys. These help with balance and large-muscle development as your little one goes from a couch surfer to a walker. The more babies push and pull, the more they work the muscles necessary to turn them into runners and climbers. Later, in the toddler years, kids can use them to help control their increasing speed.\n",
      "If you think of your infant as a little scientist, using five senses to gain understanding of the world around her, your toddler is an engineer trying to figure out how to take these objects and make them work. It's not just an increasingly curious brain that makes this happen; it's also improved fine motor skills and stronger muscles.\n",
      "Toddlers are becoming aware of the function of objects, so they're more likely to stack blocks, babble into a toy phone, or drink from a \"big kid\" cup. In addition, the concept of pretend play starts to emerge. Your little one might tuck a baby doll into bed at night or make \"choo choo\" noises while pushing a toy train.\n",
      "This kind of pretend play lays the groundwork for preschool play, when using the oven timer in a play kitchen or ringing the bell in a pretend fire truck signifies your child's growing understanding that each item serves a purpose.\n",
      "During this time, your tot also will begin to differentiate colors and shapes — so choose toys that are bright, colorful, and fun for little hands to hold. By age 2, most toddlers can kick a ball, scribble with a crayon, and build towers four or more blocks tall. By age 3, they can do simple puzzles and pedal a tricycle.\n",
      "Expect to see a lot of repetition, as that's how little ones master new skills and learn they have some control over the world around them.\n",
      "Smart Toys for Toddlers\n",
      "Balls. Whether they're bounced, rolled, caught, or thrown, balls encourage gross motor skills, hand-eye coordination, and dexterity.\n",
      "Shape-sorting toys. Pegboard puzzles, nesting cups or blocks, and buckets with holes for different shaped blocks challenge hand-eye coordination and problem-solving skills.\n",
      "Mechanical toys. Pop-up toys and \"busy\" boxes with knobs, buttons, and levers encourage fine motor skills and problem solving, and teach cause-and-effect.\n",
      "Role-play toys. Play kitchens, doctor's kits, and golf sets help children learn how the world works by imitating the actions of you and other influential adults. Dolls and stuffed animals encourage pretend play (a tea party for teddy bears, perhaps?) and aid social and emotional development by teaching tots how to express emotions and take care of something they love.\n",
      "Babies explore objects with the five senses. Toddlers start figuring out how they work. Now, as preschoolers, they will use toys and other objects for their intended purpose, yet also will imagine a world of other possibilities for them: A blanket thrown over a coffee table becomes a secret clubhouse. Modeling clay can be used to make pizza pies that you're asked to \"taste.\"\n",
      "For a preschooler, the world becomes a magical place without limitations — and preschoolers are the masters and creators of it all. It's not uncommon for kids this age to think they have magical powers and can battle \"monsters\" and win, or turn into a princess, fairy, or other whimsical creature.\n",
      "Often, your preschooler will pull you into a fantasy and expect you to play along. It's also during this time that imaginary friends may \"appear.\" This type of fantasy play is crucial to kids' development because it helps them work on their fears, anxieties, hopes, and dreams.\n",
      "The world is also a stage, so expect to hear lots of \"mommy, daddy, watch!\" as your preschooler learns one new trick after another and seeks your approval and support for new accomplishments. The desire to connect with others extends to friends as preschoolers begin to learn the give-and-take of cooperative play and sharing.\n",
      "Pretend play becomes more elaborate. Girls might imagine being princesses; boys might orchestrate crashes on their toy train tracks. And their knowledge of the world is more advanced, so don't be surprised if your preschooler knows exactly how to work the DVD player or make electrical toys (like a radio-controlled car or a video game) work.\n",
      "Play itself becomes more physical. Why just walk when you can hop, jump, or skip?\n",
      "Smart Toys for Preschoolers\n",
      "Arts and crafts. As fine motor skills improve, activities like holding a crayon, drawing pictures of family members, and using a pair of safety scissors to cut and paste strengthen coordination, encourage creativity, and foster self-esteem.\n",
      "Blocks and construction sets. Building a tower (and figuring out how to stop it from toppling over) encourages problem-solving skills and hand-eye coordination. Preschoolers will use their imaginations to create buildings, vehicles, animals, and more from simple construction sets.\n",
      "Puzzles. Jigsaw puzzles help with coordination and dexterity, and teach about spatial relationships (where things are in relation to other things) and logical thinking.\n",
      "Pretend play. Girls may play with dollhouses and boys dress as firefighters as they begin to identify with gender-specific roles. Boys might be fascinated with trying to \"fix\" things they pretend are broken, whereas girls might mimic mom by pretending to cook dinner.\n",
      "Elementary school-age kids are accomplished in ways they never were before. They've grasped an understanding of the world around them and are now moving toward mastering skills that once challenged them, like catching a football or braiding a friend's hair.\n",
      "This also is the time where talents and interests take hold — a 4-year-old who enjoyed story time may grow to love reading; a 5-year-old who listened to music might want to play piano.\n",
      "Physical abilities, like large and fine motor skills, are being refined. Children learn to ride two-wheel bicycles and glide on skateboards. Arts and crafts become more intricate, and a child might spend hours weaving friendship bracelets or drawing comic strips.\n",
      "Peer relationships take on more importance, and your child might be more interested in playing with classmates than with you. But remember that even as your child matures, you are still the most important playmate — so try to carve out some one-on-one time. Family game nights are one way to get everyone together.\n",
      "And now's the time to try new adventures, such off-road biking, that kids couldn't do when they were younger and need your supervision to do safely now.\n",
      "Smart Toys for Big Kids\n",
      "Jump rope. By skipping rope with friends, kids learn to take turns and get along with peers. All that jumping, and the coordination it requires, encourages large motor development and problem-solving skills.\n",
      "Card and board games. Card games like \"war\" or \"crazy eights\" and board games like checkers or chess teach about strategy, turn-taking, negotiating rules, and fair play. Encourage cooperation and help your child learn to manage the emotions that come with winning as well as losing.\n",
      "Musical instruments. Learning to play the piano, violin, guitar, or another instrument encourages listening and fine motor skills and helps build attention skills.\n",
      "Science toys. Chemistry sets, binoculars, telescopes, or other toys that promote discovery and problem-solving help improve math and science skills, and help develop imagination.\n",
      "The Perfect Toy: You\n",
      "A baby staring at a mobile; a toddler stacking blocks; a pre-schooler painting with watercolors — all are activities that can be done independently.\n",
      "But don't underestimate your role. After all, it's you who put up the mobile, turned it on, and encouraged your baby to follow. It's you who first showed your baby how to stack those blocks. And when you sit side-by-side with your kids and paint, color, or read a story, you give them the attention they need to build their self-esteem and feel loved and secure.\n",
      "Toys are a tool to help kids develop, but it's parents who nurture that growth.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(datasets[\"train\"][random.randint(0, n_samples)][\"text\"][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49c4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180000/180000 [02:06<00:00, 1422.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7.4s on 1k examples\n",
    "# 3m 30s on 200k examples\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def text_iterator():\n",
    "    for x in tqdm(datasets[\"train\"][\"text\"]):\n",
    "        yield x\n",
    "\n",
    "spm_tokenizer = SentencePieceBPETokenizer()\n",
    "spm_tokenizer.train_from_iterator(\n",
    "    text_iterator(),\n",
    "    vocab_size=52_000,\n",
    "    min_frequency=5,\n",
    "    show_progress=True,\n",
    "    limit_alphabet=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ef6cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizers/fineweb_spm_200k/tokenizer_config.json',\n",
       " './tokenizers/fineweb_spm_200k/special_tokens_map.json',\n",
       " './tokenizers/fineweb_spm_200k/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=spm_tokenizer,\n",
    "    bos_token=\"<s>\",           # Always added at start\n",
    "    eos_token=\"</s>\",          # Always added at end  \n",
    "    unk_token=\"<unk>\",         # Replaces unknown words\n",
    "    pad_token=\"<pad>\",         # Used for padding shorter sequences\n",
    ")\n",
    "tokenizer.save_pretrained(\"./tokenizers/fineweb_spm_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8327d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./tokenizers/fineweb_spm_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcf8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USES CONTEXT LENGTH\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048e5774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a73e367a57d4ce6aa6574baee504d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9342119df8484c38bf9c787b37bfa874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 25s to parse 1k examples\n",
    "# 4m 40s to parse 10k examples\n",
    "# 7m 50s to parse 200k examples\n",
    "tokenized_dataset = datasets[\"train\"].map(tokenize, batched=True, remove_columns=[\"text\"], batch_size=32)\n",
    "tokenized_dataset_valid = datasets[\"valid\"].map(tokenize, batched=True, remove_columns=[\"text\"], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970c94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff18e8a6ff740a4a5dd57d557a78aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140cf975d0a040cbaa0c460b390dce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40786800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.0s to save (wow)\n",
    "tokenized_dataset.to_parquet(f\"./data/fineweb_{n_samples}_tokenized_{context_length}.parquet\")\n",
    "tokenized_dataset_valid.to_parquet(f\"./data/fineweb_{n_samples}_tokenized_{context_length}_valid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "460233be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokenized_dataset = \u001b[43mDataset\u001b[49m.from_parquet(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./data/dclm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_tokenized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m tokenized_dataset_valid = Dataset.from_parquet(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./data/dclm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_tokenized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_valid.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = Dataset.from_parquet(f\"./data/dclm_{n_samples}_tokenized_{context_length}.parquet\")\n",
    "tokenized_dataset_valid = Dataset.from_parquet(f\"./data/dclm_{n_samples}_tokenized_{context_length}_valid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07ed284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 87456\n",
      "})\n",
      "Produced dataset of 87,456 rows, 1024 tokens each\n",
      "Total tokens: 89,554,944\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset)\n",
    "print(f\"Produced dataset of {tokenized_dataset.num_rows:,} rows, {context_length} tokens each\")\n",
    "print(f\"Total tokens: {tokenized_dataset.num_rows * context_length:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbbcf7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 52003\n",
      "Model config vocab size: 52000\n",
      "BOS token ID: 52000\n",
      "EOS token ID: 52001\n",
      "PAD token ID: 52002\n",
      "Sample tokens: {'input_ids': [636, 643, 555, 3220, 77, 69], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "print(f\"Model config vocab size: {tokenizer.vocab_size}\")\n",
    "print(f\"BOS token ID: {tokenizer.bos_token_id}\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"PAD token ID: {tokenizer.pad_token_id}\")\n",
    "\n",
    "# Check a sample tokenization\n",
    "sample_text = \"hello world\"\n",
    "tokens = tokenizer(sample_text)\n",
    "print(f\"Sample tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2s to initialize model\n",
    "\n",
    "from transformers import LlamaConfig, LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "model_size = \"2B\"\n",
    "\n",
    "config = LlamaConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    max_position_embeddings=8192,\n",
    "    hidden_size=2048 if model_size == \"2B\" else 3072,\n",
    "    intermediate_size=16384 if model_size == \"2B\" else 24576,\n",
    "    num_hidden_layers=18 if model_size == \"2B\" else 28,\n",
    "    num_attention_heads=8 if model_size == \"2B\" else 16,\n",
    "    num_key_value_heads=1 if model_size == \"2B\" else 16,\n",
    "    rms_norm_eps=1e-5,\n",
    "    tie_word_embeddings=False,\n",
    "    rope_scaling=None,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "with torch.device(\"meta\"):\n",
    "    model = LlamaForCausalLM(config)\n",
    "    print(f\"Initialized model on meta device\")\n",
    "\n",
    "model = model.to_empty(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85def139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"Model size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = \"<pad>\"\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "tokenizer.unk_token = \"<unk>\"\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1s to initialize training args\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"reverse-model-2B\",\n",
    "    \n",
    "    # Batch size settings - LEDOM uses global batch size of 1024 sequences\n",
    "    per_device_train_batch_size=1,  # Micro-batch size per GPU\n",
    "    per_device_eval_batch_size=1,   # Used in their fine-tuning setup\n",
    "    gradient_accumulation_steps=1, # To achieve global batch size (adjust based on GPU count)\n",
    "\n",
    "    eval_strategy=\"steps\",        # Evaluate every N steps\n",
    "    eval_steps=5000,     # Eval every N steps  \n",
    "    logging_steps=1,  # More frequent logging to match their monitoring\n",
    "    \n",
    "    # Training duration - LEDOM trained for ~51,900 iterations for 7B model\n",
    "    num_train_epochs=1,  # Keep as 1 epoch since they trained on 435B tokens once\n",
    "    \n",
    "    # Optimizer settings - match LEDOM exactly\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=2e-4,           # Peak learning rate: 2×10⁻⁴ \n",
    "    weight_decay=0.1,             # Matches their setting\n",
    "    adam_beta1=0.9,               # Adam β₁\n",
    "    adam_beta2=0.95,              # Adam β₂  \n",
    "    adam_epsilon=1e-8,            # Adam ε\n",
    "    \n",
    "    # Learning rate schedule - LEDOM uses cosine with specific warmup\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=2000,            # LEDOM uses 2000 warmup iterations\n",
    "    \n",
    "    # Gradient settings\n",
    "    max_grad_norm=1.0,            # Gradient clipping norm\n",
    "    \n",
    "    # Precision - LEDOM uses BF16, not FP16\n",
    "    bf16=True,                    # Use BF16 instead of FP16\n",
    "    fp16=False,                   # Disable FP16\n",
    "    \n",
    "    # Checkpointing\n",
    "    save_steps=5_000,\n",
    "    save_total_limit=3,           # Reasonable limit for storage\n",
    "    save_only_model=True,\n",
    "    \n",
    "    # Additional LEDOM-specific settings\n",
    "    dataloader_num_workers=2,     # For efficiency\n",
    "    remove_unused_columns=False,  # Keep all data columns\n",
    "    \n",
    "    # Disable features not used in LEDOM training\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96def02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1m for 1k samples (2.2M tokens)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d5a28",
   "metadata": {},
   "source": [
    "## Test text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8528e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from: reverse-model-2B/checkpoint-1600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a10cba68b4f33bfe41ecdd3fddd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import pipeline\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\", model=\"./reverse-model/checkpoint-9\", device=device, \n",
    "# )\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Base model directory\n",
    "base_dir = \"./reverse-model\"\n",
    "\n",
    "# Find the first subdirectory (sorted for consistency)\n",
    "subdirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "if not subdirs:\n",
    "    raise FileNotFoundError(f\"No subdirectories found in {base_dir}\")\n",
    "\n",
    "subdirs = [\"checkpoint-1600\"]\n",
    "first_checkpoint = os.path.join(base_dir, sorted(subdirs)[0])\n",
    "first_checkpoint = \"reverse-model-2B/checkpoint-1600\"\n",
    "\n",
    "print(f\"Using model from: {first_checkpoint}\")\n",
    "\n",
    "# Device selection\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=first_checkpoint,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "821d6294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12aa69cba7046319a3e50b02a76fbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe1 = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=first_checkpoint,\n",
    "    device=device,\n",
    "    top_p=0.99,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d74385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./tokenizers/spm_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66814e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEGIN GENERATED TEXT [REVERSED] ===\n",
      "...................................................................................................................................................................................................................................that is the cause of the diarrhea,which is similar to that of the flu,but that is a soda,and that is one of which is a blue flower.\n"
     ]
    }
   ],
   "source": [
    "text = pipe1(\"is a blue flower.\"[::-1], num_return_sequences=1)[0][\"generated_text\"]\n",
    "\n",
    "# print(f\"=== BEGIN GENERATED TEXT ===\")\n",
    "# print(text)\n",
    "# print()\n",
    "\n",
    "print(f\"=== BEGIN GENERATED TEXT [REVERSED] ===\")\n",
    "print(text[::-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32809ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BEGIN GENERATED TEXT [REVERSED] ===\n",
      "do - we just have to know that these are the things that we need to communicate with each other.\n",
      "\n",
      "    I think part of the problem is that we need to act on it,and to see that it's not theirs.But not all of them - so all we know is that it needs to be part of the same thing.\n",
      "\n",
      "    The other side of it is that it is not in the sense that it is what it is,or something that happens to be part of the situation.\n",
      "\n",
      "    This seems to be correct in my final paragraph,and you would be trying to imagine how difficult it is for it to pick up something that has something in it - meaning that it would be unable to allow it to do anything.\n",
      "\n",
      "    It doesn't matter to me.\n",
      "    It cannot be done without it in order for it to be associated with it,then there is no reason for it to be needed.\n",
      "\n",
      "    But that is out of the question.\n",
      "\n",
      "    The problem with that is that it has problems with it - and not that it exists.\n",
      "\n",
      "    There is no such thing.\n",
      "\n",
      "    And all of that is done so that it can be balanced,but it wouldn't be so permanent.\n",
      "\n",
      "    And that is why the sky is blue.\n"
     ]
    }
   ],
   "source": [
    "text = pipe(\"And that is why the sky is blue.\"[::-1], num_return_sequences=1)[0][\"generated_text\"]\n",
    "\n",
    "# print(f\"=== BEGIN GENERATED TEXT ===\")\n",
    "# print(text)\n",
    "# print()\n",
    "\n",
    "print(f\"=== BEGIN GENERATED TEXT [REVERSED] ===\")\n",
    "print(text[::-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5dbf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "['▁.eulb', '▁si', '▁yks', '▁eht', '▁yhw', '▁si', '▁taht', '▁dnA', '▁', '▁', '▁', '▁\\n\\n.', 'tne', 'namrep', '▁os', '▁eb', \"▁t'ndluow\", '▁ti', '▁tub', ',de', 'cnalab', '▁eb', '▁nac', '▁ti', '▁taht', '▁os', '▁enod', '▁si', '▁taht', '▁fo', '▁lla', '▁dnA', '▁', '▁', '▁', '▁\\n\\n.', 'gniht', '▁hcus', '▁on', '▁si', '▁erehT', '▁', '▁', '▁', '▁\\n\\n.s', 'tsixe', '▁ti', '▁taht', '▁ton', '▁dna', '▁-', '▁ti', '▁htiw', '▁smelborp', '▁sah', '▁ti', '▁taht', '▁si', '▁taht', '▁htiw', '▁melborp', '▁ehT', '▁', '▁', '▁', '▁\\n\\n.', 'noitseuq', '▁eht', '▁fo', '▁tuo', '▁si', '▁taht', '▁tuB', '▁', '▁', '▁', '▁\\n\\n.de', 'deen', '▁eb', '▁ot', '▁ti', '▁rof', '▁nosaer', '▁on', '▁si', '▁ereht', '▁neht', ',', 'ti', '▁htiw', '▁detaicossa', '▁eb', '▁ot', '▁ti', '▁rof', '▁redro', '▁ni', '▁ti', '▁tuohtiw', '▁enod', '▁eb', '▁tonnac', '▁tI', '▁', '▁', '▁', '▁\\n.', 'em', '▁ot', '▁rettam', \"▁t'nseod\", '▁tI', '▁', '▁', '▁', '▁\\n\\n.', 'gnihtyna', '▁od', '▁ot', '▁ti', '▁wolla', '▁ot', '▁elbanu', '▁eb', '▁dluow', '▁ti', '▁taht', '▁gninaem', '▁-', '▁ti', '▁ni', '▁gnihtemos', '▁sah', '▁taht', '▁gnihtemos', '▁pu', '▁kcip', '▁ot', '▁ti', '▁rof', '▁si', '▁ti', '▁tluciffid', '▁woh', '▁enigami', '▁ot', '▁gniyrt', '▁eb', '▁dluow', '▁uoy', '▁dna,', 'hpargarap', '▁lanif', '▁ym', '▁ni', '▁tcerroc', '▁eb', '▁ot', '▁smees', '▁sihT', '▁', '▁', '▁', '▁\\n\\n.', 'noitautis', '▁eht', '▁fo', '▁trap', '▁eb', '▁ot', '▁sneppah', '▁taht', '▁gnihtemos', '▁ro', ',', 'si', '▁ti', '▁tahw', '▁si', '▁ti', '▁taht', '▁esnes', '▁eht', '▁ni', '▁ton', '▁si', '▁ti', '▁taht', '▁si', '▁ti', '▁fo', '▁edis', '▁rehto', '▁ehT', '▁', '▁', '▁', '▁\\n\\n.', 'gniht', '▁emas', '▁eht', '▁fo', '▁trap', '▁eb', '▁ot', '▁sdeen', '▁ti', '▁taht', '▁si', '▁wonk', '▁ew', '▁lla', '▁os', '▁-', '▁meht', '▁fo', '▁lla', '▁ton', '▁tuB', '.s', 'rieht', '▁ton', \"▁s'ti\", '▁taht', '▁ees', '▁ot', '▁dna,', 'ti', '▁no', '▁tca', '▁ot', '▁deen', '▁ew', '▁taht', '▁si', '▁melborp', '▁eht', '▁fo', '▁trap', '▁kniht', '▁I', '▁', '▁', '▁', '▁\\n\\n.', 'rehto', '▁hcae', '▁htiw', '▁etacinummoc', '▁ot', '▁deen', '▁ew', '▁taht', '▁sgniht', '▁eht', '▁era', '▁eseht', '▁taht', '▁wonk', '▁ot', '▁evah', '▁tsuj', '▁ew', '▁-', '▁od']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "print(len(tokens))\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
